---
# defaults file for hadoop

# the list of RPMS are Redhat release dependent (in the vars/RedHatX.yml)
hadoop_rpms:

# journalnode and zkfc related packages
hadoop_hdfs_journalnode_package: "hadoop-hdfs-journalnode-2.6.0+cdh5.11.1+2400-1.cdh5.11.1.p0.6.el7.x86_64"
hadoop_hdfs_zkfc_package: "hadoop-hdfs-zkfc-2.6.0+cdh5.11.1+2400-1.cdh5.11.1.p0.6.el7.x86_64"

#Hadoop rpm artifactory url
rhel_centos_6: '{{(ansible_distribution == "CentOS" or ansible_distribution == "RedHat") and ansible_distribution_major_version == "6"}}'
rhel_centos_7: '{{(ansible_distribution == "CentOS" or ansible_distribution == "RedHat") and ansible_distribution_major_version == "7"}}'

# remove java versions other than Oracle JRE
hadoop_remove_java_versions:
  - java-1.8.0-openjdk
  - jdk

# Name of the cluster for HA
hadoop_cluster_name: HA-cluster

# kerberos related settings
hadoop_merged_keytab: "hdfs-merged"
hadoop_namenode_keytab_path: "/etc/security/keytabs/{{ hadoop_merged_keytab }}.keytab"
hadoop_datanode_keytab_path: "/etc/security/keytabs/{{ hadoop_merged_keytab }}.keytab"
hadoop_journalnode_keytab_path: "/etc/security/keytabs/{{ hadoop_merged_keytab }}.keytab"
hadoop_zkfc_keytab_path: "/etc/security/keytabs/{{ hadoop_merged_keytab }}.keytab"
hadoop_web_keytab_path: "/etc/security/keytabs/{{ hadoop_merged_keytab }}.keytab"

#hadoop configuration directory (contains hadoop-env.sh for configuration of any special env or JVM options)
hadoop_conf_dir: /etc/hadoop/conf
hadoop_pid_dir: /var/run/hadoop-hdfs

#hadoop data directory 
hadoop_data_directory: /opt/app/hadoop-hdfs

# journal nodes directory
dfs_journalnode_edits_dir: /opt/app/hadoop-hdfs/journal

#hdfs global gid and uid used while hdfs group/user creation
hdfs_grp_id: 494
hdfs_usr_id: 497

#hadoop vars used by hdfs-site.xml.j2
hadoop_logs_dir: /var/log/hadoop-hdfs/
hadoop_dfs_home_dir: /opt/app/hadoop-hdfs
hadoop_dfs_name_dir: /opt/app/hadoop-hdfs/dfs/name
hadoop_dfs_data_dir: /opt/app/hadoop-hdfs

# HDFS Namenode ports
hadoop_namenode_rpc_port: 8020
hadoop_namenode_http_port: 50070
hadoop_namenode_https_port: 50470

# HDFS ZKFC Port
hadoop_zkfc_port: 8019

# HDFS Journalnode ports
hadoop_journalnode_edits_port: 8485
hadoop_journalnode_http_port: 8480
hadoop_journalnode_https_port: 8481

# HDFS Datanode ports
hadoop_datanode_port: 11999
hadoop_datanode_secure_port: 1004
hadoop_datanode_ipc_port: 50020
hadoop_datanode_http_port: 50075
hadoop_datanode_http_secure_port: 1006
hadoop_datanode_https_port: 50475

# Zookeeper client port
zk_port: 9094

# Prometheus JMX Exporter port numbers for Hadoop deamons
# These variables should be same as what we have in prometheus_eporter role defaults
# In future we may want to move to group variables instead of having them inside here
exporter_install_dir: "/opt/app/prometheus"
hadoop_namenode_jmxexporter_port: "9104"
hadoop_resource_manager_jmxexporter_port: "9106"
hadoop_datanode_jmxexporter_port: "9105"
hadoop_node_manager_jmxexporter_port: "9107"
jmx_exporter_config_dir: "/etc/prometheus/jmx_exporter"
jmx_exporter_base_dir: "{{ exporter_install_dir }}/jmx_exporter"
jmx_exporter_version: "0.10.linux-amd64"
jmx_exporter_archive_base: "jmx_prometheus_javaagent-{{jmx_exporter_version}}"
jmx_exporter_jar: "jmx_prometheus_javaagent.jar"
hadoop_libexec_dir: "/usr/lib/hadoop/libexec"
hadoop_sbin_dir: "/usr/lib/hadoop/sbin"

# by default TLS is always turned on for fresh deployment
hadoop_enable_tls: false

# by default, kerberos auth is disabled for zkfc-zk
hadoop_enable_zkfc_kerberos: false

# remember to manually stop hdfs before running a script with hadoop_reinstall set to TRUE
hadoop_reinstall: False

### hdfs ssl-client.xml and ssl-server.xml variables
hdfs_truststore_reload_inverval: 1000

# set the hdfs hostnames in /etc/hosts
hdfs_set_etc_hosts: true
