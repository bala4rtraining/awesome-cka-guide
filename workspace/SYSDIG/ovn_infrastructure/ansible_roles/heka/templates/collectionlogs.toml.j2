## {{ ansible_managed }}

[LogstreamerInput_collectionjob]
type="LogstreamerInput"
log_directory = "/var/log/ovn_clearing_jobs"
file_match = '(?P<logname>(DeliveryJob|PCR-.+))\.log'
differentiator = ["ovn_clearing_jobs/", "logname", ".log"] 
decoder = "collectionjob_transform_decoder"
splitter = "SplitterForCollectionJobLogs"

[SplitterForCollectionJobLogs]
type = "RegexSplitter"
delimiter = '\n(\[\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}\])'
delimiter_eol = false

[collectionjob_transform_decoder]
type = "PayloadRegexDecoder"
match_regex = '[\n]?\[(?P<Timestamp>(?P<Date>\d{4}-\d{2}-\d{2}) (?P<Time>\d{2}:\d{2}:\d{2}))\]\[(?P<Severity>[A-Z]+)\]\[(?P<class>\S+)\] (?P<Xmessage>[^$]+)'
timestamp_layout = "2006-01-02 15:04:05"
timestamp_location = "UTC"
[collectionjob_transform_decoder.severity_map]
TRACE = 8
DEBUG = 7
INFO = 6
NOTICE = 5
WARN = 4
ERROR = 3
CRITICAL = 2
[collectionjob_transform_decoder.message_fields]
Payload = "%Xmessage%"

[ESJsonEncoder_collectionjob]
type="ESJsonEncoder"
es_index_from_timestamp = true
{% raw %}
index = "ovn_clearing_jobs-%{%Y.%m.%d}"
{% endraw %}


[ElasticSearchOutput_collectionjob]
type="ElasticSearchOutput"
message_matcher = "Logger =~ /^ovn_clearing_jobs.*/"
{% if elasticsearch_client_ssl_enabled == "true" %}
server = "https://{{ elasticsearch_host }}:{{ elasticsearch_port }}"
{% else %}
server = "http://{{ elasticsearch_host }}:{{ elasticsearch_port }}"
{% endif %}
flush_interval = 5000
flush_count = 100
encoder = "ESJsonEncoder_collectionjob"
    {% if elasticsearch_client_ssl_enabled == "true" %}
    [ElasticSearchOutput_collectionjob.tls]
    cert_file = "/etc/pki/tls/elasticsearch-client/certs/{{ inventory_hostname }}.pem"
    key_file = "/etc/pki/tls/elasticsearch-client/private/{{ inventory_hostname }}.pem"
    root_cafile = "/etc/pki/tls/elasticsearch-client/certs/bundle.pem"
    client_auth = "RequireAndVerifyClientCert"
    prefer_server_ciphers = true
    min_version = "TLS12"
    {% endif %}
